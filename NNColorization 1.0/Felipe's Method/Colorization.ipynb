{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor \n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InsertBorder(image):\n",
    "    new_image = np.zeros((image.shape[0]+2, image.shape[1]+2, image.shape[2]))\n",
    "    \n",
    "    #Copying the image \n",
    "    for i in range(0,image.shape[0]):\n",
    "        for j in range(0,image.shape[1]):\n",
    "            new_image[i+1,j+1,:] = image[i,j,:]\n",
    "    \n",
    "    #Inserting the border\n",
    "    new_image[0,:,:] = new_image[1,:,:]\n",
    "    new_image[new_image.shape[0]-1,:,:] = new_image[new_image.shape[0]-2,:,:]\n",
    "    \n",
    "    new_image[:,0,:] = new_image[:,1,:]\n",
    "    new_image[:,new_image.shape[1]-1,:] = new_image[:,new_image.shape[1]-2,:]\n",
    "    return np.uint8(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGR2YCrCb(image):\n",
    "    \n",
    "    Y, Cr, Cb = cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb))\n",
    "    return cv2.merge([Y, Cr, Cb])\n",
    "\n",
    "def YCrCb2BGR(image):\n",
    "    B, G, R = cv2.split(cv2.cvtColor(image, cv2.COLOR_YCrCb2BGR))\n",
    "    return cv2.merge([B, G, R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatures(image):\n",
    "    \n",
    "    new_image = InsertBorder(image)\n",
    "    imageYCbCr = BGR2YCrCb(new_image)\n",
    "    imageY = imageYCbCr[:,:,0]\n",
    "    \n",
    "    k = 0;\n",
    "    features = np.zeros(((image.shape[0])*(image.shape[1]),9))\n",
    "    \n",
    "    for i in range(1,imageY.shape[0]-1):\n",
    "        for j in range(1,imageY.shape[1]-1):\n",
    "            features[k,0] = imageY[i-1,j-1]\n",
    "            features[k,1] = imageY[i,j-1]\n",
    "            features[k,2] = imageY[i+1,j-1]\n",
    "            features[k,3] = imageY[i-1,j]\n",
    "            features[k,4] = imageY[i,j]\n",
    "            features[k,5] = imageY[i+1,j]\n",
    "            features[k,6] = imageY[i-1,j+1]\n",
    "            features[k,7] = imageY[i,j+1]\n",
    "            features[k,8] = imageY[i+1,j+1]\n",
    "            k += 1\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractTargets(image):\n",
    "    imageYCbCr = BGR2YCrCb(image)\n",
    "    \n",
    "    imageCr = imageYCbCr[:,:,1]\n",
    "    imageCb = imageYCbCr[:,:,2]\n",
    "    \n",
    "    ImageCbVec = np.reshape(imageCb, (imageCb.shape[0]*imageCb.shape[1],1))\n",
    "    ImageCrVec = np.reshape(imageCr, (imageCr.shape[0]*imageCr.shape[1],1))\n",
    "\n",
    "    target = np.concatenate((ImageCbVec, ImageCrVec), 1)\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecoverImage(imagevec,imageY,m,n):\n",
    "    \n",
    "    imageCb = np.reshape(imagevec[:,0], (m,n))\n",
    "    imageCr = np.reshape(imagevec[:,1], (m,n))\n",
    "    imageYCbCr = cv2.merge([np.uint8(imageY),np.uint8(imageCr), np.uint8(imageCb)])\n",
    "    \n",
    "    image = YCrCb2BGR(imageYCbCr)\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPSNR(true, pred):\n",
    "    giantTrueMatrix = np.concatenate((true[0], true[1], true[2]), 1)\n",
    "    giantPredMatrix = np.concatenate((pred[0], pred[1], pred[2]), 1)\n",
    "\n",
    "    return cv2.PSNR(giantTrueMatrix, giantPredMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('paisagem5.jpg')\n",
    "Data = ExtractFeatures(image)/255\n",
    "Target = ExtractTargets(image)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestAccuracy = 0\n",
    "BestNeurons = 0\n",
    "for neurons in range(200,201):\n",
    "    for i in range(0,5):\n",
    "        NeuralNetwork = MLPRegressor(hidden_layer_sizes=(neurons,neurons), max_iter=2000, verbose=False) \n",
    "        NeuralNetwork.fit(Data, Target)  \n",
    "        accuracy = NeuralNetwork.score(Data,Target)\n",
    "\n",
    "        if accuracy > BestAccuracy:\n",
    "            BestAccuracy = accuracy\n",
    "            BestNeurons = neurons\n",
    "            BestNN = NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor Acuracia:\n",
      "0.6872403100672879\n",
      "Quantidade de Neuronios:\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(\"Melhor Acuracia:\")\n",
    "print(BestAccuracy)\n",
    "\n",
    "print(\"Quantidade de Neuronios:\")\n",
    "print(BestNeurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = 255*BestNN.predict(Data)  \n",
    "\n",
    "imageYCbCr = BGR2YCrCb(image)\n",
    "imageY = imageYCbCr[:,:,0]\n",
    "\n",
    "m = image.shape[0]\n",
    "n = image.shape[1]\n",
    "\n",
    "recover = RecoverImage(predictions,imageY,m,n)\n",
    "\n",
    "#plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#plt.imshow(cv2.cvtColor(np.uint8(recover), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.70900002950695"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPSNR(image,np.uint8(recover))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"paisagem200*200.png\",recover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
